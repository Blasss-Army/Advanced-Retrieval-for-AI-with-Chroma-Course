{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Q&A over Documents\n",
    "\n",
    "An example might be a tool that would allow you to query a product catalog for items of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook we are gonna create a Chain that can answer questions related with a document. So it´s very interesting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE general idea is that we wanna use LLM along with all our documents,\n",
    "but there is a key issue. LLM can only just inspect a few thousand words at a time. \n",
    "\n",
    "So with large documents we have a problem. And here is where world embedings and Vectors database come to play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMBEDINGS = Embeddings are numerical representations of objects (pieces of text) that capture their semantic meaning of the piece of text. These representations are typically high-dimensional vectors....\n",
    "\n",
    "Embeddings enable similarity searches, where objects that are semantically similar are close to each other in the vector space. This is useful in tasks like recommendation systems and semantic search (Pieces of text with similar content will have similar vectors.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we have three sentences: one is about a dog life, other is about cats life and last one is about how ferrary is the best car brand.\n",
    "\n",
    "The emmbedings vectors related with cat and dog sentences would have higher simmilarity than the car one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VECTOR DATABASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It´s a way to store the vector representations we´ve created before with the embbedings transformation.\n",
    "\n",
    "We populate the BBDD wich chunks of text from the document. \n",
    "\n",
    "So the first step is dividing all the info in a document into smaller chunks of text. Wich it will be useful  couz maybe we are not able to pass all the document info into the LLM in once\n",
    "\n",
    "Second we create embbedings for each chunk\n",
    "\n",
    "third we store the chunks into the Vector database.\n",
    "\n",
    "\n",
    "So when we wanna do RAG, retrieval information, Whe create an embbeding of the query we are passing.\n",
    "\n",
    "Then we compare the embbeding of the query with the stored chunk embbedings, therefore it will return the  most similar vector embbedings in our Vector BBDD.\n",
    "\n",
    "And we can pass those into the prompt of LLM for getting our final answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector database is a specialized type of database designed to store and manage high-dimensional vectors, which are numerical representations of data. These vectors can represent various types of data, such as text, images, audio, and more. Here’s a detailed look at what vector databases are and how they work:\n",
    "\n",
    "Key Features of Vector Databases\n",
    "Storage of Vectors:\n",
    "\n",
    "Vector databases store data as vectors, which are fixed-length lists of numbers. Each vector represents the features of the data in a high-dimensional space1.\n",
    "Similarity Search:\n",
    "\n",
    "One of the primary functions of vector databases is to perform similarity searches. This involves finding vectors that are closest to a given query vector, which is useful for tasks like semantic search, recommendation systems, and image retrieval2.\n",
    "Approximate Nearest Neighbor (ANN) Algorithms:\n",
    "\n",
    "Vector databases often implement ANN algorithms to efficiently search for similar vectors. Techniques like Hierarchical Navigable Small World (HNSW) graphs, Locality-sensitive Hashing (LSH), and Product Quantization (PQ) are commonly used1.\n",
    "Applications:\n",
    "\n",
    "Semantic Search: Finding documents or data that are semantically similar to a query.\n",
    "Recommendation Systems: Suggesting items similar to user preferences.\n",
    "Image and Audio Retrieval: Searching for images or audio files that are similar to a given example.\n",
    "Large Language Models (LLMs): Enhancing the performance of LLMs by retrieving relevant context1.\n",
    "How Vector Databases Work\n",
    "Vectorization:\n",
    "\n",
    "Data is transformed into vectors using machine learning models, embeddings, or feature extraction techniques. For example, a sentence can be converted into a vector using word embeddings like Word2Vec or BERT2.\n",
    "Storage and Indexing:\n",
    "\n",
    "The vectors are stored in the database, and indexing techniques are applied to facilitate efficient similarity searches.\n",
    "Query Processing:\n",
    "\n",
    "When a query vector is provided, the database uses ANN algorithms to quickly find the nearest vectors in the high-dimensional space.\n",
    "Example Use Case\n",
    "Imagine you have a collection of images and you want to find images similar to a given one. You would:\n",
    "\n",
    "Convert all images into vectors using a feature extraction model.\n",
    "Store these vectors in a vector database.\n",
    "When a query image is provided, convert it into a vector and use the database to find the most similar image vectors.\n",
    "Popular Vector Databases\n",
    "Some well-known vector databases include:\n",
    "\n",
    "Pinecone\n",
    "Milvus\n",
    "Weaviate\n",
    "FAISS (Facebook AI Similarity Search)\n",
    "These databases are optimized for handling high-dimensional data and performing fast similarity searches, making them essential tools in modern AI and machine learning applications23.\n",
    "\n",
    "Would you like to know more about a specific vector database or how to implement one in a project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "import os\n",
    "import os\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "API_BASE = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "MODEL = os.getenv('OPENAI_MODEL_NAME')\n",
    "API_VERSION = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##########################\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"Please list all your shirts with sun protection \\\n",
    "in a table in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "- The notebook uses `langchain==0.0.179` and `openai==0.27.7`\n",
    "- For these library versions, `VectorstoreIndexCreator` uses `text-davinci-003` as the base model, which has been deprecated since 1 January 2024.\n",
    "- The replacement model, `gpt-3.5-turbo-instruct` will be used instead for the `query`.\n",
    "- The `response` format might be different than the video because of this replacement model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_replacement_model = OpenAI(temperature=0, \n",
    "                               model='gpt-3.5-turbo-instruct')\n",
    "\n",
    "response = index.query(query, \n",
    "                       llm = llm_replacement_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step By Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embeddings.embed_query(\"Hi my name is Harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Please suggest a shirt with sunblocking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.call_as_llm(f\"{qdocs} Question: Please list all your \\\n",
    "shirts with sun protection in a table in markdown and summarize each one.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"Please list all your shirts with sun protection in a table \\\n",
    "in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(query, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embeddings,\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
