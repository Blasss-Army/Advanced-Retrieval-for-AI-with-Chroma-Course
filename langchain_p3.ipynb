{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chain is the most important part of LangChain, it combines an LLM with the prompt, and with this block you creat a bunch of them to carry an operation in your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "API_BASE = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "MODEL = os.getenv('OPENAI_MODEL_NAME')\n",
    "API_VERSION = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##########################\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''España es un país situado en el suroeste de Europa, \n",
    "en la península ibérica. Limita al norte con Francia y Andorra, \n",
    "al oeste con Portugal, y al sur con el mar Mediterráneo y el océano Atlántico.\n",
    " Su capital es Madrid, una ciudad vibrante y llena de historia.\n",
    "\n",
    "España es conocida por su rica cultura y patrimonio. \n",
    "Desde la arquitectura de Gaudí en Barcelona hasta los museos de arte en Madrid, \n",
    "como el Museo del Prado, el país ofrece una gran variedad de experiencias culturales. \n",
    "Además, España es famosa por su gastronomía, que incluye platos como la paella, \n",
    "el gazpacho y las tapas.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we initialize the LLM with a high temperature to get a fun descriptions\n",
    "\n",
    "#This doesnt work -> llm = ChatOpenAI(temperature=0.9, model=MODEL)\n",
    "\n",
    "llm = AzureChatOpenAI(temperature=0.9, \n",
    "                      api_key=API_KEY, \n",
    "                      api_version=API_VERSION,\n",
    "                      azure_endpoint=API_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we initialazie the prompt, is gonna take a varible product...\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\\\n",
    "        JUST RETURN THE NAME UP TO 6 WORDS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are gonna use a chain to combine these two things.\n",
    "#We create the chain object.\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Royal Rest Linens'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "\n",
    "# Then we run the Chain object we´ve created before\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential chains, run a sequence of chains one after another.\n",
    "\n",
    "The output of one chain is the input of another chain\n",
    "\n",
    "There is two type of sequential chains:\n",
    "* Simple sequetial chains : Single input/outpu\n",
    "* SequentialChains: Multiuple inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create LLM object\n",
    "#This doesnt work -->>> llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "llm = AzureChatOpenAI(temperature=0.9, \n",
    "                      api_key=API_KEY, \n",
    "                      api_version=API_VERSION,\n",
    "                      azure_endpoint=API_BASE)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create the sequential chain by joining chain_one and chain_two\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mChoosing the best name for a company that specializes in Queen Size Sheet Sets involves considering factors like brand identity, target audience, and uniqueness. Here are a few suggestions that might resonate well:\n",
      "\n",
      "1. **Queen's Comfort**\n",
      "2. **Royal Rest Linens**\n",
      "3. **Majestic Sheets**\n",
      "4. **Queen's Haven Bedding**\n",
      "5. **Regal Slumber Sheets**\n",
      "6. **Crown Sleep Sets**\n",
      "7. **Monarch Linens**\n",
      "8. **Queen's Dream Sheets**\n",
      "9. **Sovereign Sleep Co.**\n",
      "10. **Imperial Bedding Solutions**\n",
      "\n",
      "Remember to check for trademark availability and domain registration to ensure the name can be uniquely yours.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mA company specializing in Queen Size Sheet Sets, focused on luxury, comfort, and elegance, offering uniquely branded bedding solutions.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A company specializing in Queen Size Sheet Sets, focused on luxury, comfort, and elegance, offering uniquely branded bedding solutions.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we execute it for getting some reuslts\n",
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This doesnt work -->>> llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "llm = AzureChatOpenAI(temperature=0.9, \n",
    "                      api_key=API_KEY, \n",
    "                      api_version=API_VERSION,\n",
    "                      azure_endpoint=API_BASE)\n",
    "\n",
    "#For first chane, we´re gona take the review and translate it to english\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very inportant that the input keys and output keys must be presicely name correctly and similar.\n",
    "\n",
    "1st Chain output_key -> Englis_Review //  2nd Chain input_key -> Englis_Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second chain create a summary of that review tranlation\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd chain will return the original language of that review\n",
    "\n",
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4th chain will take multiple inputs, summary input, and original language.and\n",
    "# And it will return a summary in the original language\n",
    " \n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': 'España es un país situado en el suroeste de Europa, \\nen la península ibérica. Limita al norte con Francia y Andorra, \\nal oeste con Portugal, y al sur con el mar Mediterráneo y el océano Atlántico.\\n Su capital es Madrid, una ciudad vibrante y llena de historia.\\n\\nEspaña es conocida por su rica cultura y patrimonio. \\nDesde la arquitectura de Gaudí en Barcelona hasta los museos de arte en Madrid, \\ncomo el Museo del Prado, el país ofrece una gran variedad de experiencias culturales. \\nAdemás, España es famosa por su gastronomía, que incluye platos como la paella, \\nel gazpacho y las tapas.',\n",
       " 'English_Review': \"Spain is a country located in the southwest of Europe, on the Iberian Peninsula. It borders France and Andorra to the north, Portugal to the west, and the Mediterranean Sea and the Atlantic Ocean to the south. Its capital is Madrid, a vibrant city full of history.\\n\\nSpain is known for its rich culture and heritage. From Gaudí's architecture in Barcelona to the art museums in Madrid, such as the Prado Museum, the country offers a wide range of cultural experiences. Additionally, Spain is famous for its cuisine, which includes dishes such as paella, gazpacho, and tapas.\",\n",
       " 'summary': 'Spain, located in southwest Europe, is renowned for its rich culture, historical architecture, vibrant capital Madrid, and famous cuisine like paella and tapas.',\n",
       " 'followup_message': '¡Qué maravilla es España! Sin duda, su ubicación en el suroeste de Europa le ha permitido desarrollar una cultura tan rica y variada. La arquitectura histórica es verdaderamente impresionante y nos transporta a épocas pasadas llenas de historia y arte. Madrid, su capital vibrante, nunca deja de sorprender con su energía y vida nocturna. Y, por supuesto, la gastronomía es un capítulo aparte. ¿Quién podría resistirse a un buen plato de paella o una selección de deliciosas tapas? España realmente tiene algo especial que ofrecer a cada visitante.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "overall_chain(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complicate operation, \n",
    "when you have multiple subchains and each one is especializied in a particular input.\n",
    "\n",
    "You can have a router Chain , which decides wich subchain to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the router_chain typically uses a language model (LLM) to analyze the input and determine which destination_chain to route the request to. The LLM evaluates the input based on predefined criteria or prompts and then selects the most appropriate subchain to handle the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have some subjects templates, the main idea is: When the Router chain calls\n",
    "# a subchai , this chain should be the one related with the field \n",
    "\n",
    "\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will indicate the Router chain which template promt it should it use base \n",
    "# on the follow description.\n",
    "\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This doesnt work -->>> llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "llm = AzureChatOpenAI(temperature=0.9, \n",
    "                      api_key=API_KEY, \n",
    "                      api_version=API_VERSION,\n",
    "                      azure_endpoint=API_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the chains that will be called by the router Chain,\n",
    "# here we are creatin all the subchains\n",
    "\n",
    "destination_chains = {}\n",
    "\n",
    "\n",
    "# prompt_infos is expected to be a list of dictionaries, \n",
    "# where each dictionary contains information about a specific prompt, \n",
    "# including its name and template.\n",
    "\n",
    "for p_info in prompt_infos:\n",
    "\n",
    "\n",
    "    #Extract information and create chains\n",
    "\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "\n",
    "    #All sub chains have been added to the dict 'destination_chains'\n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['physics: Good for answering questions about physics',\n",
       " 'math: Good for answering math questions',\n",
       " 'History: Good for answering history questions',\n",
       " 'computer science: Good for answering computer science questions']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'physics: Good for answering questions about physics\\nmath: Good for answering math questions\\nHistory: Good for answering history questions\\ncomputer science: Good for answering computer science questions'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the Default Chain, when the Router Chain doesnt know wich chain to call,\n",
    "# by default it will call this chain\n",
    "\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the template that is gonna be used by the LLM\n",
    "\n",
    "\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **format** method is used to replace the placeholder {destinations} in the MULTI_PROMPT_ROUTER_TEMPLATE with the value of destinations_str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet is creating a PromptTemplate for the router, which will use the router_template to decide how to route inputs to the appropriate destination_chain.\n",
    "\n",
    "* template=router_template: This uses the router_template created earlier, which includes the formatted list of destination chains.\n",
    "\n",
    "* input_variables=[\"input\"]: This specifies that the template will take an input variable. This is the input that the router will analyze to decide which subchain to route to.\n",
    "\n",
    "* output_parser=RouterOutputParser(): This is crucial. The RouterOutputParser is responsible for interpreting the output of the language model and determining which destination_chain to use based on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Here we create the router Prompt, by passing it the 'router_template' as argument\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "\n",
    "    #IMPORTAT WE HAVE HERE THE RouterOutputParser\n",
    "    #It will help the router to decide wich subchanges to route\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "\n",
    "#Here we create our Router Chain\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can create the overall chain\n",
    "# it has the router chain, destination chain and default chain\n",
    "\n",
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, \n",
    "                         verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the electromagnetic radiation emitted by an idealized object known as a black body, which absorbs all incident radiation, regardless of frequency or angle of incidence. A perfect black body is a theoretical construct that emits radiation in a characteristic spectrum solely determined by its temperature, according to Planck's law. \\n\\nThis radiation has a continuous spectrum, starting from near zero at low frequencies, rising to a peak at a frequency that increases with temperature, and then decreasing again at higher frequencies. The radiation includes all wavelengths, and the peak of the emission shifts to shorter wavelengths as the temperature of the black body increases—this is known as Wien’s Displacement Law.\\n\\nAn excellent real-world approximation of a black body is a cavity with a small hole; any radiation entering the hole is unlikely to escape, as it will be absorbed or reflected multiple times within the cavity. The concept of black body radiation is fundamental in the development of quantum mechanics and helps to explain phenomena like the color of stars and the cosmic microwave background radiation of the universe.\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'What is 2 + 2?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To solve the question \"What is 2 + 2?\", let\\'s break it down:\\n\\n1. Identify the numbers involved: We have two instances of the number 2.\\n2. Understand the operation: The operation here is addition, which involves combining the values of the numbers.\\n3. Perform the addition: Add the first 2 to the second 2.\\n\\n\\\\[ 2 + 2 = 4 \\\\]\\n\\nSo, the answer is 4.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Every cell in our body contains DNA because DNA carries the genetic instructions necessary for the development, functioning, growth, and reproduction of all living organisms, including humans. Here are some key reasons why DNA is present in nearly every cell:\\n\\n1. **Genetic Blueprint:** DNA contains the genetic blueprint or instructions needed for the synthesis of proteins, which are crucial for the structure and function of cells. Proteins perform most of the work within cells and are essential for the body's structure, function, and regulation of tissues and organs.\\n\\n2. **Cell Function and Identity:** DNA provides the information needed for cells to carry out their specific roles. Different cell types activate different genes within the DNA, allowing them to perform specialized functions, such as muscle contraction or nerve impulse transmission.\\n\\n3. **Reproduction and Growth:** DNA is necessary for cell division and growth. When cells divide, DNA is replicated so that each new cell inherits a complete set of genetic instructions. This is vital for tissue growth and repair, as well as for reproduction.\\n\\n4. **Genetic Continuity:** DNA ensures the continuity of genetic information from one generation to the next. Through reproduction, DNA is passed from parents to offspring, ensuring that the characteristics of a species are maintained over time.\\n\\n5. **Maintenance and Repair:** DNA contains the instructions for the repair and maintenance of cells. It helps to coordinate responses to damage or changes in the cellular environment, enabling cells to adapt and survive under various conditions.\\n\\nWhile most cells in the body contain a complete set of DNA, there are a few exceptions, such as red blood cells, which lose their nuclei and DNA during maturation to optimize their capacity for oxygen transport.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
